apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: binance-collector
  namespace: airflow
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: docker.io/library/spark:4.0.0
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///opt/spark-work-dir/financial-platform/spark-scripts/collect_binance_data.py"
  arguments:
    - "s3a://bronze/crypto/binance"
  sparkVersion: 4.0.0
  restartPolicy:
    type: Never
  
  hadoopConf:
    fs.s3a.endpoint: "http://minio.minio.svc.cluster.local:9000"
    fs.s3a.access.key: "minioadmin"
    fs.s3a.secret.key: "minioadmin123"
    fs.s3a.path.style.access: "true"
    fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
    fs.s3a.connection.ssl.enabled: "false"
  
  sparkConf:
    spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
  
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 4.0.0
      layer: "bronze"
      source: "binance"
    serviceAccount: spark-operator-spark
    
    initContainers:
      - name: git-sync
        image: registry.k8s.io/git-sync/git-sync:v4.3.0
        args:
          - --repo=https://github.com/l-margotti/financial-platform.git
          - --branch=main
          - --depth=1
          - --root=/work-dir
          - --one-time
        volumeMounts:
          - name: work-dir
            mountPath: /work-dir
    
    volumeMounts:
      - name: work-dir
        mountPath: /opt/spark-work-dir
  
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 4.0.0
      layer: "bronze"
    
    initContainers:
      - name: git-sync
        image: registry.k8s.io/git-sync/git-sync:v4.3.0
        args:
          - --repo=https://github.com/l-margotti/financial-platform.git
          - --branch=main
          - --depth=1
          - --root=/work-dir
          - --one-time
        volumeMounts:
          - name: work-dir
            mountPath: /work-dir
    
    volumeMounts:
      - name: work-dir
        mountPath: /opt/spark-work-dir
  
  volumes:
    - name: work-dir
      emptyDir: {}